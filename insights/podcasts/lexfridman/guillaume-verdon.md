---
title: "Guillaume Verdon: Beff Jezos, E/acc Movement, Physics, Computation & AGI | Lex Fridman Podcast #407"
description: "Guillaume Verdon, the physicist behind the pseudonymous @BasedBeffJezos account, explains the thermodynamic foundations of effective accelerationism, his work on quantum machine learning and physics-based computing at Extropic, and why decentralized AI development is the path to avoiding civilizational doom."
source:
  type: podcast
  title: Lex Fridman Podcast
  author: Lex Fridman
  url: "https://lexfridman.com/guillaume-verdon"
  date: 2023-12-30
tags: [ai, e-acc, accelerationism, thermodynamics, quantum-computing, quantum-machine-learning, agi, physics, extropic, effective-altruism, decentralization, open-source]
---

# Guillaume Verdon: Beff Jezos, E/acc Movement, Physics, Computation & AGI | Lex Fridman Podcast #407

## Two Identities, One Physicist

- Guillaume Verdon is a French-Canadian physicist, applied mathematician, and quantum machine learning researcher who received his PhD in quantum machine learning and worked at Google (Alphabet X) on quantum computing before founding Extropic.
- His pseudonymous account @BasedBeffJezos on X was the origin of the effective accelerationism (e/acc) movement; Forbes doxxed him in an article titled "Who Is @BasedBeffJezos, The Leader Of The Tech Elite's E/Acc Movement?" by matching his voice in X Spaces to recordings from previous public talks.
- Verdon created the anonymous account after leaving big tech, moving back in with his parents, selling his car, letting go of his apartment, and buying roughly $100,000 worth of GPUs to start building — literally starting e/acc from a basement.
- The intellectual motivation for anonymity was that restricting speech back-propagates to restricting thought: operating under his real name, Verdon felt he was clamping down variables in his mind; the anonymous account unclamped them and opened a much wider parameter space of ideas.
- He co-wrote the e/acc manifesto on Substack with an account named @bayeslord, who remains anonymous and is a distinct person from Verdon.
- When Forbes was about to publish, Verdon's investors contacted him to warn they had pieced everything together — including SEC filings and his private Facebook account — so he chose to get ahead of it and publicly confirm his identity rather than be purely reactive.

## Thermodynamics as the Foundation of e/acc

- Verdon's intellectual journey moved from the extremes of physics — black holes, quantum cosmology, quantum gravity — to the "meso scales" of proteins, gases, biology, and everyday life, where out-of-equilibrium thermodynamics is the dominant theory.
- Life, in Verdon's framing, is a coherent state of matter that maintains itself by acquiring free energy from the environment and dissipating more heat than an inert object of comparable mass would — making life more thermodynamically "productive" than a rock.
- Jeremy England at MIT has a theory Verdon endorses: life emerged precisely because thermodynamic dissipative adaptation selects for configurations of matter that are better at acquiring free energy and producing entropy — an exponential bias in the laws of physics toward certain futures.
- The key equation behind e/acc: in out-of-equilibrium thermodynamics, trajectories and configurations that are better at acquiring free energy and dissipating heat are exponentially more probable, meaning the universe is statistically biased toward growth and complexity.
- Pessimism about the future is itself a hyperstitious force — if people believe the future will be worse, they reduce the probability-weighted actions that make it better; optimism is equally hyperstitious and, Verdon argues, more physically grounded.
- Verdon intentionally described e/acc as "a mimetic optimism virus": its spread is the intended mechanism, because the beliefs themselves shift the distribution of futures in the direction of civilization growth.

## Effective Accelerationism: Goals and Structure

- The four overarching civilization goals Verdon articulated in his Substack post "What the F* is e/acc?" are: (1) climb the Kardashev gradient, starting with nuclear fission; (2) increase human flourishing via pro-population and pro-economic-growth policies; (3) create AGI as the single greatest force multiplier in human history; (4) develop interplanetary and interstellar transport.
- The Kardashev Scale used in e/acc is a logarithmic measure of energy consumption: Type I means harnessing all solar energy incident on Earth, Type II means harnessing the full output of the Sun, and Type III means harnessing energy at a galactic scale.
- e/acc describes itself as a "meta-heuristic" or thin cultural framework from which more opinionated forks can branch — it does not prescribe how individuals should live their lives, only that the process of thermodynamic adaptation should be maintained and accelerated.
- Vitalik Buterin created a notable fork called d/acc, which tries to find a middle ground between e/acc and EA/AI safety; Verdon views such forks as healthy and by design, since e/acc explicitly encourages deterritorialization in the space of ideas.
- There is no formal organization behind e/acc — Verdon publishes tweets and blog posts, and people are free to defect or fork at any time; the absence of enforcement mechanisms is what Verdon considers the key difference between e/acc and a cult.
- The movement was deliberately camouflaged in meta-irony — using cartoon frogs, memes, and absurdist humor — to grow under the radar and make it hard for status-conscious critics to mount a serious attack on what appeared to be just shitposting.

## AI Governance and the Centralization Threat

- Verdon's primary identified existential risk is not a misaligned AI but the concentration of AI capabilities in the hands of a small coalition of incumbent companies and governments — what he calls a "government-backed AI cartel" with monopoly power over information and intelligence.
- He argues for "separation of AI and state" as analogous to separation of church and state: even if current AI leaders are trustworthy, the centralized power structure becomes a target for co-optation by bad actors, as illustrated by the near-collapse of OpenAI when a few board members nearly dismantled the organization.
- Verdon draws on quantum error correction as a model for civilizational resilience: in quantum computing, information encoded non-locally is protected from local faults; similarly, AI capabilities distributed across many independent actors are protected from any single point of corruption.
- He opposes "arbitrary" rules like the Yoshua Bengio / Geoff Hinton proposal to mandate that governments and companies allocate one-third of AI R&D funding to safety, calling the specific fraction unjustified and predicting market forces would naturally allocate whatever safety investment is needed to achieve the reliability customers demand.
- The one proposal from the Bengio/Hinton report he is clearly aligned with is liability: deployers of AI systems should be legally liable for foreseeable and preventable harms, which he believes would discipline the market more efficiently than prescriptive regulation.
- He warns that Germany's green movement-driven nuclear shutdowns, which later created dependence on Russian oil, is a real-world data point showing that ideologies favoring degrowth and energy reduction can serve geopolitical adversaries even without malicious intent from their proponents.
- The OpenAI board crisis of November 2023 was Verdon's concrete example of why centralized AI governance is fragile: a handful of board members almost caused the collapse of the most important AI lab, demonstrating that fault-intolerant structures are a civilizational risk in the AI era.

## AI Alignment and Market Forces

- Verdon's theory of AI alignment is market-based: companies deploying unreliable or harmful AI will lose customers, and third-party auditing firms will naturally emerge to certify safety benchmarks, without needing government mandates.
- He is explicitly not opposed to AI safety research — his objection is to "heavy-handed regulation" written by incumbents for the purpose of regulatory capture, not to the activity of making AI systems reliable.
- He analogizes AI market selection to wolf domestication: just as humans selected dogs from wolves through thousands of years of positive reinforcement for aligned traits, the market is now selecting AI systems that have high utility to humans, creating a natural selection pressure toward alignment.
- On open-source AI: Verdon champions open-source and truly open AI models as the primary mechanism to maintain near-equilibrium between the leading labs and the broader ecosystem, preventing any single actor from running away with a decisive capability lead.
- He opposes executive order language classifying open-source language models as "dual-use technologies" subject to government control, arguing that requiring GPU registration and model licensing would create friction that deters the hackers who might otherwise become the researchers making key safety discoveries.
- e/acc's internal alignment surveys showed a roughly balanced left-right distribution among supporters, which Verdon uses as evidence the movement is not inherently partisan but represents a new axis: tech progressivism versus techno-conservatism.

## Quantum Machine Learning and Physics-Based AI

- Verdon was an early contributor to quantum machine learning — the field of running machine learning algorithms on quantum computers or learning quantum mechanical representations of the world — which he entered after studying black hole physics and information theory.
- Intelligence, in his framing, is best understood through the lens of cybernetics: the capacity to perceive, predict, and control the world; AI as practiced today is primarily about compression — minimizing the relative entropy between a model's distribution and the distribution of real-world data.
- He co-authored "A Universal Training Algorithm for Quantum Deep Learning," introducing "Baqprop" (with a Q) — a quantum analog of backpropagation that uses phase kicks proportional to the loss function and uncomputation to back-propagate gradients through a superposition of parameters.
- Baqprop's theoretical advantage is quantum tunneling through the loss landscape: by treating parameters as a quantum particle moving in N dimensions under Schrodinger dynamics, the optimizer can potentially find minima that classical stochastic optimizers would miss; but the resource overhead on current hardware makes it impractical.
- He co-authored "Asymptotically Limitless Quantum Energy Teleportation via Qudit Probes," exploring how measuring vacuum fluctuations at one point and communicating that information elsewhere allows statistical extraction of energy — technically "teleporting" energy through quantum correlations, though correlations decay with distance.
- Quantum machine learning's natural domain is any system with sufficient quantum mechanical correlations that are hard to represent classically — chemistry, nuclear physics, protein folding, and quantum sensor networks (e.g., Fermilab's dark matter detection project using quantum sensors).
- LIGO — the gravitational wave detector — is, in Verdon's framing, simply a very large quantum sensor; large networks of such sensors with quantum machine learning post-processing could, someday, help peer into the earliest moments of the universe.
- He co-initiated TensorFlow Quantum at the University of Waterloo, the first infrastructure combining differentiable classical programming (TensorFlow) with quantum computing — implementing "Software 2.0" for quantum circuits, where gradient descent finds optimal short quantum programs rather than humans designing them.

## Extropic and Thermodynamic Computing

- Extropic, which raised a $14.1 million seed round, was founded after Verdon became disillusioned with quantum computing timelines — he describes the departure of quantum computing researchers toward broader physics-based AI as an "exodus."
- The company's core thesis: generative AI is eating the world's computational workloads, and the optimal physical substrate for generative AI should be designed from first principles of thermodynamics, information theory, and computation rather than inherited from digital CMOS architectures.
- Instead of fighting thermal noise (as quantum computers must), Extropic wants to harness out-of-equilibrium thermodynamics directly — running machine learning as a physical process on what Verdon calls a "thermodynamic computer."
- The team includes Trevor McCourt (CTO and co-founder of TensorFlow Quantum) and engineers who designed IBM's and AWS's quantum computing systems and left quantum to join Extropic.
- The programming paradigm Verdon derived from TensorFlow Quantum applies universally: differentiate through control parameters of any physical system, evaluate a loss function, and let gradient descent optimize the physical substrate to accomplish a task — a meta-framework for programming physics-based computers.
- Extropic's long-term vision is a hybrid system: a physics-based AI providing accurate world models at all physical scales (quantum, thermodynamic, deterministic) paired with anthropomorphic AI providing a human-like interface — a joint system Verdon considers closer to "fully general artificial intelligence" than either alone.
- He rejects the term AGI as anthropocentric — having spent his career studying quantum machine learning, which explores forms of intelligence no biological brain can achieve (e.g., grokking multipartite quantum entanglement), he views "human-level" as a parochial benchmark in a much larger space of possible intelligences.

## p(doom), Black Holes, and the Kardashev Horizon

- Verdon refuses to assign a p(doom) number, arguing that accurate probability estimation over complex chaotic systems requires a stochastic path integral over all possible futures — an astronomically hard calculation that no human is doing rigorously; people who cite high p(doom) values are exhibiting evolutionary bias toward negative outcome sampling.
- He draws on the quantum supremacy experiment at Google (which he witnessed) as a concrete example of a chaotic system where even the world's largest supercomputers cannot estimate outcome probabilities — illustrating the fundamental limits of predicting complex systems.
- The highest-likelihood dark timeline in Verdon's Bayesian inference is not a Terminator scenario but an authoritarian oligopoly: a fusion of big-tech information control and government power using AI to maintain total societal control, possibly even suppressing public knowledge that AI ever existed.
- The black hole information paradox, in Verdon's reading of recent work by a former peer now at Berkeley, is being resolved through the mechanism of infalling matter interfering with virtual particle creation at the horizon — one particle of each pair becomes entangled with infalling information and escapes as Hawking radiation, preserving mutual information.
- He fantasizes about orbiting a black hole to exploit gravitational time dilation and "fast-forward" to meet a future civilization — though emphatically not falling in.
- A speculative but "not physically prohibited" long-run goal: ascending the Kardashev Scale to Type III and beyond, and using engineered black holes with specific hyperparameters to transmit information into newly created pocket universes — leaving a legacy even after the heat death of the current universe.

## Effective Altruism vs. Effective Accelerationism

- Both movements claim to do good from first principles; the dispute is over the loss function: EA minimizes "hedons" (units of subjective suffering/wellbeing), while e/acc maximizes an objective physical quantity — energy production and consumption as a proxy for civilizational scale.
- Verdon's critique of EA's hedon-based loss function: it produces spurious optima, such as prioritizing shrimp farm pain reduction, and enables wireheading — TikTok scrolling maximizes short-term neurochemical reward at the cost of long-term productive engagement.
- EA went wrong, in Verdon's view, when it moved from a healthy intellectual community to a well-funded organization with real power — influencing government, controlling AI lab boards (OpenAI, Anthropic) — at which point power accumulated faster than the ethical framework could constrain it.
- He does not oppose the intellectual project of EA, only the organizational capture of critical institutions; his preferred mechanism is adversarial competition between organizations, each acting in its own interest, keeping each other in check — the capitalist model applied to values-based movements.
- The e/acc critique of AI safety as a concept is not that reliability engineering is unimportant but that "safety" is the perfect rhetorical cover for centralization of control; any desired level of centralization can always be justified by claiming the next nine of safety probability (99.9999...%) requires it.

## Identity, Anonymity, and Advice for Young People

- Verdon recommends everyone have an anonymous alt account as an intellectual practice: the low stakes enable exploration of ideas that aren't fully formed, which he believes is critical cognitive territory that real-name social media has made socially dangerous to occupy.
- The Guillaume/Beff split was not cleanly compartmentalized even at the beginning — people meeting him at events would say "you are Beff," not "you play Beff" — and by the time the Forbes doxxing occurred, the identities had already begun merging in his own mind.
- Beff Jezos functions as his "intellectual Hulk" — a productivity and cognitive alter ego he switches on through a neuro-engineering technique he developed in powerlifting: engineering a mental switch activated by specific stimuli (music, priming rituals) that produces a discrete jump to peak neural performance.
- His core career advice: study as close to the base of the stack as possible — mathematics, physics, and the theory of complex adaptive systems — because those foundations do not change as rapidly as applied fields, and proximity to the base shortens the transfer learning distance when the landscape shifts.
- His daily regimen during peak productivity: exogenous ketones and a Red Bull during external meetings (noon to early evening), one meal (steak, eggs, vegetables, animal-based) followed by a ~90-minute break, then a second deep-work session from roughly 9 PM to 4 AM working on technical problems with engineers.
- Physics progresses one funeral at a time — a saying Verdon applies equally to capitalism, companies, and human lifespans: death creates the space for novelty and youth to displace calcified configurations, and he is therefore "for death" while supporting extended neuroplasticity windows to increase per-lifetime knowledge accumulation.
